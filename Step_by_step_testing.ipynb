{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # operating system functions like renaming files and directories\n",
    "import shutil  # recursive file and directory operations\n",
    "import glob  # pattern matching for paths\n",
    "import pandas as pd  # data mangling and transforming\n",
    "import bandicoot as bc  # MIT toolkit for creating bandicoot indicators\n",
    "import argparse  # entering flags from the cmd line\n",
    "import gnuper as gn  # the package in question\n",
    "from pyspark.sql import SparkSession  # using spark context for big data files\n",
    "from pyspark.sql.functions import col  # needed for function over each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_flag = True\n",
    "bc_flag = True\n",
    "verbose = True\n",
    "clean_up = False\n",
    "raw_data_path = '../../CDR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes for this session\n",
    "att = gn.Attributes(mp_flag=mp_flag,\n",
    "                    bc_flag=bc_flag,\n",
    "                    hdfs_flag=hdfs_flag,\n",
    "                    verbose=verbose,\n",
    "                    clean_up=clean_up,\n",
    "                    raw_data_path=raw_data_path,\n",
    "                    cap_coords=[15.500654, 32.559899],  # capital gps\n",
    "                    weekend_days=[5, 6],\n",
    "                    sparkmaster='yarn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark environment for Part 1 created!\n"
     ]
    }
   ],
   "source": [
    "# # --- Part 1 --- (Preprocessing of raw files and saving by user)\n",
    "spark = SparkSession.builder.master(att.sparkmaster)\\\n",
    "    .appName('cdr_extraction_part1').getOrCreate()\n",
    "print('Spark environment for Part 1 created!')\n",
    "\n",
    "# ## antennas datasets\n",
    "# read cell and antenna locations into a spark dataframe (sdf)\n",
    "raw_locations = gn.read_as_sdf(file=att.raw_locations,\n",
    "                               sparksession=spark, header=False,\n",
    "                                colnames=['cell_id', 'antenna_id',\n",
    "                                          'longitude', 'latitude'],\n",
    "                                query=gn.queries.general.raw_locations_query())\n",
    "# create raw table to query and cache it as we will query it for every day\n",
    "raw_locations.createOrReplaceTempView('table_raw_locations')\n",
    "spark.catalog.cacheTable('table_raw_locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antenna SDF & table created!\n",
      "Starting with Level 0: General preprocessing of raw CDRs.\n"
     ]
    }
   ],
   "source": [
    "# solely antenna locations as sdf (= ignore cell_id)\n",
    "# FILE: save as 1 csv next to the raw data as we will need it later on\n",
    "raw_locations.selectExpr('antenna_id', 'longitude', 'latitude')\\\n",
    "    .dropDuplicates().write.csv(att.antennas_file,\n",
    "                                mode='overwrite', header=True)\n",
    "print('Antenna SDF & table created!')\n",
    "\n",
    "# ## Preprocessing\n",
    "# **Level 0**: General preprocessing of raw call detail records\n",
    "# Storing daily files in a unified dataframe\n",
    "print('Starting with Level 0: General preprocessing of raw CDRs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
