1. install python3 on the virtual machine
2. install modules via "pip install -r requirements.txt"

Script has been built using SPARK version 2.2.1
  3. install java environment "sudo apt-get install default-jre"
  4. install scala "sudo apt-get install scala"
  5. download spark
     "wget http://archive.apache.org/dist/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz"
  6. unzip "sudo tar -zxvf spark-2.2.1-bin-hadoop2.7.tgz"
  7. and remove "rm spark-2.2.1-bin-hadoop2.7.tgz"

8. if spark can't be found by the python script,
   open "python3" and type the following:
  "import findspark
  findspark.init('PATH_TO_SPARK')"
  (PATH_TO_SPARK is the path to the spark installation)

9. inside the attributes class adjust the following parameters if necessary:
  9.1 path to the raw data (Line 9)
  9.2 name of the raw locations file (Line 13, please ensure that this file
      is in the same folder as the raw daily files)

10. additional parameters like coordinates for the capital or the multiplicator
    can be adjusted inside the script (preprocessing_script.py) at line 47 ff.

10. then go back to the terminal and run python script like this:
"rm -f preprocessing.log && python3 preprocessing_script.py >> preprocessing.log 2>&1"
(preprocessing.log will log all the output and errors for easier debugging)
